
__import__('pysqlite3')
import sys
sys.modules['sqlite3'] = sys.modules.pop('pysqlite3')
# ===================================================================================

import streamlit as st
import json
import os
import glob
import uuid
import chromadb
from chromadb.utils import embedding_functions
import google.generativeai as genai

# --- C·∫§U H√åNH TRANG ---
st.set_page_config(page_title="Chatbot Ph√°p Lu·∫≠t", layout="wide")
st.title("ü§ñ Chatbot T∆∞ V·∫•n Ph√°p Lu·∫≠t & C∆∞ Tr√∫")

COLLECTION_NAME = "dichvucong_db_final_v5" # ƒê·ªïi t√™n m·ªõi ƒë·ªÉ x√≥a cache c≈©

# --- C·∫§U H√åNH API ---
st.sidebar.header("‚öôÔ∏è C·∫•u h√¨nh")
api_key = st.secrets.get("GEMINI_API_KEY")
if not api_key:
    api_key = st.sidebar.text_input("Nh·∫≠p Google AI API Key:", type="password")
    if not api_key:
        st.warning("üëâ Vui l√≤ng nh·∫≠p API Key.")
        st.stop()

genai.configure(api_key=api_key)

# Ch·ªçn Model
try:
    models = [m.name for m in genai.list_models() if 'gemini' in m.name and 'generateContent' in m.supported_generation_methods]
    model_choice = st.sidebar.selectbox("Ch·ªçn Model:", models, index=0)
except:
    st.sidebar.error("L·ªói k·∫øt n·ªëi Google AI.")
    st.stop()

# ================= 3. H√ÄM N·∫†P D·ªÆ LI·ªÜU  =================
@st.cache_resource(ttl="2h")
def load_data_to_vector_db():
    try:
        # 1. Setup ChromaDB
        embedding_function = embedding_functions.SentenceTransformerEmbeddingFunction(
            model_name="keepitreal/vietnamese-sbert"
        )
        client = chromadb.Client()
        collection = client.get_or_create_collection(
            name=COLLECTION_NAME,
            embedding_function=embedding_function
        )

        # 2. N·∫øu DB ƒë√£ c√≥ d·ªØ li·ªáu th√¨ d√πng lu√¥n, kh√¥ng n·∫°p l·∫°i
        if collection.count() > 0:
            return collection, f"ƒê√£ c√≥ s·∫µn {collection.count()} chunks."

        # 3. T√¨m file JSON trong th∆∞ m·ª•c
        json_files = glob.glob("*.json")
        if not json_files:
            return None, "KHONG_TIM_THAY_FILE_JSON"

        # 4. ƒê·ªçc file
        all_docs = []
        all_ids = []
        all_metas = []
        
        file_list_str = ""
        
        for file_path in json_files:
            file_list_str += f"{file_path}, "
            with open(file_path, 'r', encoding='utf-8') as f:
                data = json.load(f)
                if isinstance(data, list):
                    for item in data:
                        content = item.get("content_text", "").strip()
                        if len(content) < 10: continue
                        
                        all_ids.append(str(uuid.uuid4()))
                        all_docs.append(content)
                        
                        # X·ª≠ l√Ω metadata an to√†n
                        meta = item.get("metadata", {}).copy()
                        meta["source_file"] = file_path
                        meta["url"] = item.get("url", "")
                        # Chroma kh√¥ng ch·ªãu value l√† None
                        clean_meta = {k: str(v) for k, v in meta.items() if v is not None}
                        all_metas.append(clean_meta)

        if not all_docs:
            return None, "FILE_RONG"

        # 5. N·∫°p Batch (ƒê·ªÉ kh√¥ng b·ªã tr√†n RAM)
        batch_size = 40
        for i in range(0, len(all_ids), batch_size):
            collection.add(
                ids=all_ids[i : i+batch_size],
                documents=all_docs[i : i+batch_size],
                metadatas=all_metas[i : i+batch_size]
            )
            
        return collection, f"Th√†nh c√¥ng! ƒê√£ n·∫°p {len(all_ids)} chunks t·ª´: {file_list_str}"

    except Exception as e:
        return None, f"LOI_HE_THONG: {str(e)}"

# --- G·ªåI H√ÄM V√Ä HI·ªÇN TH·ªä K·∫æT QU·∫¢ ---
with st.spinner("ƒêang kh·ªüi ƒë·ªông h·ªá th·ªëng tri th·ª©c..."):
    collection, status_msg = load_data_to_vector_db()

# X·ª≠ l√Ω hi·ªÉn th·ªã l·ªói/th√†nh c√¥ng
if collection is None:
    if "KHONG_TIM_THAY" in status_msg:
        st.error("‚ö†Ô∏è Kh√¥ng t√¨m th·∫•y file `.json` n√†o tr√™n GitHub. B·∫°n ƒë√£ upload file c√†o ƒë∆∞·ª£c ch∆∞a?")
    elif "LOI_HE_THONG" in status_msg:
        st.error(f"‚ùå {status_msg}")
        st.info("H√£y ki·ªÉm tra l·∫°i file requirements.txt xem c√≥ d√≤ng 'pysqlite3-binary' ch∆∞a.")
    else:
        st.error(f"‚ùå L·ªói d·ªØ li·ªáu: {status_msg}")
    st.stop()
else:
    st.sidebar.success(f"‚úÖ {status_msg}")

# ================= 4. LOGIC CHATBOT =================
def query_ai(question):
    try:
        results = collection.query(query_texts=[question], n_results=10)
        
        context = ""
        sources = []
        if results['documents']:
            for i, doc in enumerate(results['documents'][0]):
                meta = results['metadatas'][0][i]
                source_url = meta.get('url', '#')
                file_name = meta.get('source_file', '')
                context += f"- N·ªôi dung: {doc}\n- Ngu·ªìn: {file_name}\n---\n"
                sources.append(source_url)
        
        prompt = f"""B·∫°n l√† tr·ª£ l√Ω ·∫£o ph√°p lu·∫≠t. D·ª±a v√†o th√¥ng tin sau:\n{context}\n\nH√£y tr·∫£ l·ªùi c√¢u h·ªèi: {question}"""
        
        model = genai.GenerativeModel(model_choice)
        response = model.generate_content(prompt)
        return response.text, list(set(sources))
    except Exception as e:
        return f"L·ªói khi g·ªçi AI: {str(e)}", []

# Giao di·ªán Chat
if "messages" not in st.session_state:
    st.session_state.messages = [{"role": "assistant", "content": "Xin ch√†o! B·∫°n c·∫ßn t√¨m hi·ªÉu th·ªß t·ª•c g√¨?"}]

for msg in st.session_state.messages:
    st.chat_message(msg["role"]).write(msg["content"])

if prompt := st.chat_input():
    st.session_state.messages.append({"role": "user", "content": prompt})
    st.chat_message("user").write(prompt)
    
    with st.chat_message("assistant"):
        with st.spinner("ƒêang tra c·ª©u..."):
            ans, srcs = query_ai(prompt)
            st.write(ans)
            if srcs:
                st.write("**Ngu·ªìn tham kh·∫£o:**")
                for s in srcs: st.write(f"- {s}")
            st.session_state.messages.append({"role": "assistant", "content": ans})
